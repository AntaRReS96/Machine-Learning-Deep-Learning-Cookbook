{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# **Support Vector Machines (SVM)**  \n",
        "### *Maszyny wektorów nośnych*\n",
        "\n",
        "---\n",
        "\n",
        "## **English**\n",
        "\n",
        "Support Vector Machines (SVM) are powerful supervised learning algorithms used for both classification and regression tasks. The main idea behind SVM is to find the optimal hyperplane that separates different classes with the maximum margin.\n",
        "\n",
        "### **Key Concepts**\n",
        "\n",
        "1. **Support Vectors**: Data points that lie closest to the decision boundary\n",
        "2. **Hyperplane**: The decision boundary that separates classes\n",
        "3. **Margin**: The distance between the hyperplane and the nearest data points\n",
        "4. **Kernel Trick**: Transform data into higher dimensions to make it linearly separable\n",
        "\n",
        "### **Mathematical Foundation**\n",
        "\n",
        "For a binary classification problem, SVM tries to find the hyperplane defined by:\n",
        "\n",
        "$$\n",
        "w^T x + b = 0\n",
        "$$\n",
        "\n",
        "The optimization problem is:\n",
        "\n",
        "$$\n",
        "\\min_{w,b} \\frac{1}{2}||w||^2 + C\\sum_{i=1}^{n}\\xi_i\n",
        "$$\n",
        "\n",
        "Subject to:\n",
        "$$\n",
        "y_i(w^T x_i + b) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0\n",
        "$$\n",
        "\n",
        "where $C$ is the regularization parameter and $\\xi_i$ are slack variables.\n",
        "\n",
        "### **Kernel Functions**\n",
        "\n",
        "Common kernel functions include:\n",
        "- **Linear**: $K(x_i, x_j) = x_i^T x_j$\n",
        "- **Polynomial**: $K(x_i, x_j) = (x_i^T x_j + c)^d$\n",
        "- **RBF (Gaussian)**: $K(x_i, x_j) = \\exp(-\\gamma ||x_i - x_j||^2)$\n",
        "\n",
        "---\n",
        "\n",
        "## **Polish**\n",
        "\n",
        "Maszyny wektorów nośnych (SVM) to potężne algorytmy uczenia nadzorowanego używane zarówno do zadań klasyfikacji, jak i regresji. Główną ideą SVM jest znalezienie optymalnej hiperpłaszczyzny, która separuje różne klasy z maksymalnym marginesem.\n",
        "\n",
        "### **Kluczowe pojęcia**\n",
        "\n",
        "1. **Wektory nośne**: Punkty danych leżące najbliżej granicy decyzyjnej\n",
        "2. **Hiperpłaszczyzna**: Granica decyzyjna separująca klasy\n",
        "3. **Margines**: Odległość między hiperpłaszczyzną a najbliższymi punktami danych\n",
        "4. **Sztuczka jądra**: Transformacja danych do wyższych wymiarów w celu uczynienia ich liniowo separowalnymi\n",
        "\n",
        "### **Podstawy matematyczne**\n",
        "\n",
        "Dla problemu klasyfikacji binarnej, SVM próbuje znaleźć hiperpłaszczyznę zdefiniowaną przez:\n",
        "\n",
        "$$\n",
        "w^T x + b = 0\n",
        "$$\n",
        "\n",
        "Problem optymalizacji to:\n",
        "\n",
        "$$\n",
        "\\min_{w,b} \\frac{1}{2}||w||^2 + C\\sum_{i=1}^{n}\\xi_i\n",
        "$$\n",
        "\n",
        "z warunkami:\n",
        "$$\n",
        "y_i(w^T x_i + b) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0\n",
        "$$\n",
        "\n",
        "gdzie $C$ to parametr regularyzacji, a $\\xi_i$ to zmienne luzu.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear SVM Accuracy | Dokładność liniowego SVM: 0.975\n",
            "Number of support vectors | Liczba wektorów nośnych: 22\n",
            "Support vectors per class | Wektory nośne na klasę: [11 11]\n",
            "\n",
            "Classification Report | Raport klasyfikacji:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        23\n",
            "           1       0.94      1.00      0.97        17\n",
            "\n",
            "    accuracy                           0.97        40\n",
            "   macro avg       0.97      0.98      0.97        40\n",
            "weighted avg       0.98      0.97      0.98        40\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.datasets import make_classification, make_circles, make_moons\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate linearly separable data\n",
        "# Generowanie danych liniowo separowalnych\n",
        "np.random.seed(42)\n",
        "X_linear, y_linear = make_classification(n_samples=200, n_features=2, n_redundant=0, \n",
        "                                        n_informative=2, n_clusters_per_class=1, \n",
        "                                        class_sep=2, random_state=42)\n",
        "\n",
        "# Split the data\n",
        "# Podział danych\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_linear, y_linear, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "# Standaryzacja cech\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train SVM with linear kernel\n",
        "# Trenowanie SVM z jądrem liniowym\n",
        "svm_linear = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_linear.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "# Przewidywania\n",
        "y_pred_linear = svm_linear.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics\n",
        "# Obliczenie metryk\n",
        "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
        "\n",
        "print(f\"Linear SVM Accuracy | Dokładność liniowego SVM: {accuracy_linear:.3f}\")\n",
        "print(f\"Number of support vectors | Liczba wektorów nośnych: {len(svm_linear.support_)}\")\n",
        "print(f\"Support vectors per class | Wektory nośne na klasę: {svm_linear.n_support_}\")\n",
        "\n",
        "print(\"\\nClassification Report | Raport klasyfikacji:\")\n",
        "print(classification_report(y_test, y_pred_linear))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
