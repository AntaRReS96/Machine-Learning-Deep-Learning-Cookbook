# Regression Algorithms
### Algorytmy regresji

This directory contains Jupyter notebooks demonstrating various regression algorithms from scikit-learn.

## Contents | ZawartoÅ›Ä‡

### ðŸ““ Notebooks | Notatniki

1. **[Linear_Regression.ipynb](Linear_Regression.ipynb)**
   - **English**: Simple and multiple linear regression with normal equations
   - **Polish**: Prosta i wielokrotna regresja liniowa z rÃ³wnaniami normalnymi

2. **[Polynomial_Regression.ipynb](Polynomial_Regression.ipynb)**
   - **English**: Non-linear relationships using polynomial features
   - **Polish**: ZwiÄ…zki nieliniowe przy uÅ¼yciu cech wielomianowych

3. **[Ridge_Lasso_Regression.ipynb](Ridge_Lasso_Regression.ipynb)** *(Coming Soon)*
   - **English**: Regularized regression to prevent overfitting
   - **Polish**: Regresja z regularyzacjÄ… zapobiegajÄ…ca przeuczeniu

4. **[SVR_Regression.ipynb](SVR_Regression.ipynb)** *(Coming Soon)*
   - **English**: Support Vector Regression with different kernels
   - **Polish**: Regresja wektorÃ³w noÅ›nych z rÃ³Å¼nymi jÄ…drami

### ðŸŽ¯ Key Topics Covered | GÅ‚Ã³wne omawiane tematy

#### English
- **Linear Regression**: Least squares, normal equations, R-squared, RMSE
- **Polynomial Regression**: Feature engineering, basis functions, overfitting
- **Regularization**: Ridge (L2), Lasso (L1), Elastic Net penalties
- **Model Selection**: Cross-validation, bias-variance tradeoff, learning curves
- **Evaluation Metrics**: MSE, RMSE, MAE, RÂ², adjusted RÂ²

#### Polish
- **Regresja liniowa**: Najmniejsze kwadraty, rÃ³wnania normalne, R-kwadrat, RMSE
- **Regresja wielomianowa**: InÅ¼ynieria cech, funkcje bazowe, przeuczenie
- **Regularyzacja**: Kary Ridge (L2), Lasso (L1), Elastic Net
- **WybÃ³r modelu**: Walidacja krzyÅ¼owa, kompromis bias-wariancja, krzywe uczenia
- **Metryki oceny**: MSE, RMSE, MAE, RÂ², skorygowane RÂ²

### ðŸ“Š Algorithm Comparison | PorÃ³wnanie algorytmÃ³w

| Algorithm<br>Algorytm | Use Case<br>Przypadek uÅ¼ycia | Advantages<br>Zalety | Limitations<br>Ograniczenia |
|------------------------|-------------------------------|----------------------|---------------------------|
| **Linear** | Simple relationships<br>Proste zwiÄ…zki | Interpretable, fast<br>Interpretowalny, szybki | Linear assumptions<br>ZaÅ‚oÅ¼enia liniowoÅ›ci |
| **Polynomial** | Non-linear patterns<br>Wzorce nieliniowe | Flexible<br>Elastyczny | Overfitting risk<br>Ryzyko przeuczenia |
| **Ridge** | Many features<br>Wiele cech | Prevents overfitting<br>Zapobiega przeuczeniu | Shrinks coefficients<br>Zmniejsza wspÃ³Å‚czynniki |
| **Lasso** | Feature selection<br>Selekcja cech | Automatic selection<br>Automatyczna selekcja | Can eliminate important features<br>MoÅ¼e wyeliminowaÄ‡ waÅ¼ne cechy |

### ðŸ“š Required Libraries | Wymagane biblioteki

```bash
pip install numpy pandas matplotlib seaborn scikit-learn jupyter
```

### ðŸŽ“ Mathematical Foundations | Podstawy matematyczne

#### English
- **Normal Equation**: `Î¸ = (X^T X)^(-1) X^T y`
- **Cost Function**: `J(Î¸) = (1/2m) Î£(h_Î¸(x_i) - y_i)Â²`
- **Ridge Penalty**: `J(Î¸) = MSE + Î± Î£Î¸_jÂ²`
- **Lasso Penalty**: `J(Î¸) = MSE + Î± Î£|Î¸_j|`

#### Polish
- **RÃ³wnanie normalne**: `Î¸ = (X^T X)^(-1) X^T y`
- **Funkcja kosztu**: `J(Î¸) = (1/2m) Î£(h_Î¸(x_i) - y_i)Â²`
- **Kara Ridge**: `J(Î¸) = MSE + Î± Î£Î¸_jÂ²`
- **Kara Lasso**: `J(Î¸) = MSE + Î± Î£|Î¸_j|`

### ðŸš€ How to Use | Jak uÅ¼ywaÄ‡

1. **English**: 
   - Begin with Linear Regression to understand fundamentals
   - Progress to Polynomial for non-linear relationships
   - Use regularized methods for complex datasets
   - Compare different approaches on the same data

2. **Polish**:
   - Zacznij od regresji liniowej, aby zrozumieÄ‡ podstawy
   - PrzejdÅº do wielomianowej dla zwiÄ…zkÃ³w nieliniowych
   - UÅ¼ywaj metod regularyzowanych dla zÅ‚oÅ¼onych zbiorÃ³w danych
   - PorÃ³wnuj rÃ³Å¼ne podejÅ›cia na tych samych danych

### ðŸ“ˆ Performance Evaluation | Ocena wydajnoÅ›ci

#### Metrics | Metryki

- **MSE (Mean Squared Error)**: `Î£(y_true - y_pred)Â² / n`
- **RMSE (Root Mean Squared Error)**: `âˆšMSE`
- **MAE (Mean Absolute Error)**: `Î£|y_true - y_pred| / n`
- **RÂ² (Coefficient of Determination)**: `1 - SS_res/SS_tot`

### ðŸ”§ Advanced Topics | Tematy zaawansowane

- **Feature Engineering**: Polynomial features, interaction terms
- **Regularization Path**: How coefficients change with regularization strength
- **Cross-Validation**: K-fold validation for model selection
- **Learning Curves**: Training vs validation performance over time

### ðŸ”— Related Topics | PowiÄ…zane tematy

- [Classification Algorithms](../Classification/README.md)
- [Clustering Algorithms](../Clustering/README.md)
- [Feature Selection Techniques](../Feature_Selection/README.md)

---

**Note | Uwaga**: All notebooks include step-by-step explanations, mathematical derivations, and practical implementations with real datasets.

**Wszystkie notatniki zawierajÄ… objaÅ›nienia krok po kroku, wyprowadzenia matematyczne i praktyczne implementacje z rzeczywistymi zbiorami danych.**
