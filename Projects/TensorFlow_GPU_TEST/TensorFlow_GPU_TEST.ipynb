{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eaf0ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Operation tf.matmul performed on device: /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# 1 = GPU\n",
    "# 2 = CPU\n",
    "\n",
    "OPTION = 1\n",
    "\n",
    "def test_gpu():\n",
    "    # 1) Enable all logs\n",
    "    #    0 = all logs, 1 = INFO+, 2 = WARNING+, 3 = ERROR only\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "    \n",
    "    # 2) Check if TensorFlow sees any GPU\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if not gpus:\n",
    "        print(\"ðŸš« No GPU detected. TensorFlow will run on CPU.\")\n",
    "    else:\n",
    "        print(f\"âœ… GPU detected: {gpus}\\n\")\n",
    "\n",
    "    # 3) Perform a test operation and print on which device it was performed\n",
    "    a = tf.random.normal((11000, 11000))\n",
    "    b = tf.random.normal((11000, 11000))\n",
    "    c = tf.matmul(a, b)\n",
    "    \n",
    "    # c.device returns something like '/job:localhost/replica:0/task:0/device:GPU:0'\n",
    "    print(f\"Operation tf.matmul performed on device: {c.device}\")\n",
    "\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "def test_cpu():\n",
    "    # 1) Enable all logs\n",
    "    #    0 = all logs, 1 = INFO+, 2 = WARNING+, 3 = ERROR only\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "    # 2) Perform a test operation and print on which device it was performed\n",
    "    with tf.device('/CPU:0'):\n",
    "        a = tf.random.normal((11000, 11000))\n",
    "        b = tf.random.normal((11000, 11000))\n",
    "        c = tf.matmul(a, b)\n",
    "\n",
    "    # c.device returns something like '/job:localhost/replica:0/task:0/device:CPU:0'\n",
    "    print(f\"Operation tf.matmul performed on device: {c.device}\")\n",
    "\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if OPTION == 1:\n",
    "        test_gpu()\n",
    "    elif OPTION == 2:\n",
    "        test_cpu()\n",
    "    else:\n",
    "        print(\"Invalid option\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDL-COOKBOOK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
